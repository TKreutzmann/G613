{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import geopandas as gpd\n",
    "from shapely import LineString, Point\n",
    "from datetime import datetime, timedelta\n",
    "import folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "\n",
    "from pyproj import Transformer, Geod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string = \"postgresql://postgres:Nummer11!@localhost/postgres\"\n",
    "db = create_engine(conn_string)\n",
    "conn = db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#Anzahl der Tracksegmente in Tabelle finden\n",
    "tracks = \"select max(trkseg_id) from forschungsprojekt.daten\"\n",
    "trackseg_count = pd.read_sql(tracks, conn) #Erstellen 1*1 großen DF\n",
    "trackseg_count =1#= trackseg_count.values[0][0] # \"Wandelt\" zelle in Zahl um\n",
    "print(trackseg_count)\n",
    "sql = f\"SELECT * FROM forschungsprojekt.daten where trkseg_id <=1\"\n",
    "tracks_df = pd.read_sql(sql, conn)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeitabstände und Distanzen zwischen Punkten\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "tracks_df = tracks_df.sort_values(['trkseg_id','pt_id'],ascending = [True, True])\n",
    "tracks_df_time = pd.DataFrame()\n",
    "for trkseg_id in range(1,trackseg_count + 1):\n",
    "    rs = tracks_df[tracks_df['trkseg_id'] == trkseg_id]\n",
    "\n",
    "    rs['time'] = pd.to_datetime(rs['time'], format='%H:%M:%S').dt.time\n",
    "    rs = rs[~rs['time'].duplicated(keep='first')] # Doppelte Timestamps entfernen um später das Problem durch 0 zu teilen zu umgehen\n",
    "    rs['zeit_abstand'] = 0\n",
    "    rs['median_zeit_abstand'] = 0\n",
    "    rs['durch_zeit_abstand'] = 0\n",
    "\n",
    "    check_time = rs['time'].iloc[0]\n",
    "    if check_time is not None:\n",
    "        # Abstand zwischen benachbarten Punkten\n",
    "        for pt_id in range(len(rs)): \n",
    "            if rs['pt_id'].iloc[pt_id] == 1:\n",
    "                rs['zeit_abstand'] = 0\n",
    "            else:\n",
    "                last_time = rs['time'].iloc[pt_id - 1]\n",
    "                current_time = rs['time'].iloc[pt_id]\n",
    "                abstand_seconds = (current_time.hour - last_time.hour) * 3600 + \\\n",
    "                                  (current_time.minute - last_time.minute) * 60 + \\\n",
    "                                  (current_time.second - last_time.second)\n",
    "                rs['zeit_abstand'].iloc[pt_id] = abstand_seconds\n",
    "\n",
    "\n",
    "    rs['median_zeit_abstand'] = rs['zeit_abstand'].tail(-1).median()\n",
    "    rs['durch_zeit_abstand'] = rs['zeit_abstand'].tail(-1).mean()\n",
    "    \n",
    "    tracks_df_time = pd.concat([tracks_df_time, rs])\n",
    "column_names_time = tracks_df_time.columns.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentierung wenn Zeitabstand > 5*Medianzeit, Angenommen als Ausschalten des Empfängers\n",
    "tracks_df_seg = tracks_df_time\n",
    "tracks_df_seg['segment_med'] = 0\n",
    "tracks_df_seg_med = pd.DataFrame()\n",
    "segment = 0\n",
    "for trkseg_id in range(1,max(tracks_df['trkseg_id'])+1):\n",
    "    rs = tracks_df_seg[tracks_df_seg['trkseg_id'] == trkseg_id]\n",
    "    if len(rs)>=2:\n",
    "        median = rs['median_zeit_abstand'].iloc[1]*5\n",
    "        for row in range(len(rs)):\n",
    "            if (rs['zeit_abstand'].iloc[row]> median) or rs['pt_id'].iloc[row]<rs['pt_id'].iloc[row-1]:\n",
    "                segment = segment + 1\n",
    "            rs['segment_med'].iloc[row] = segment\n",
    "        tracks_df_seg_med = pd.concat([tracks_df_seg_med, rs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            lat        lon      time  trk_id  trkseg_id  pt_id    name  \\\n",
      "0     51.142741  13.500025  15:33:55       1          1      1  NoName   \n",
      "1     51.142696  13.500129  15:33:57       1          1      2  NoName   \n",
      "2     51.142648  13.500230  15:33:59       1          1      3  NoName   \n",
      "3     51.142599  13.500325  15:34:01       1          1      4  NoName   \n",
      "4     51.142555  13.500424  15:34:03       1          1      5  NoName   \n",
      "...         ...        ...       ...     ...        ...    ...     ...   \n",
      "1720  51.138904  13.500301  16:55:03       1          1   1721  NoName   \n",
      "1721  51.138956  13.500235  16:55:06       1          1   1722  NoName   \n",
      "1722  51.138992  13.500183  16:55:08       1          1   1723  NoName   \n",
      "1723  51.139029  13.500116  16:55:10       1          1   1724  NoName   \n",
      "1724  51.139062  13.500056  16:55:12       1          1   1725  NoName   \n",
      "\n",
      "      zeit_abstand  median_zeit_abstand  durch_zeit_abstand  segment_med  \\\n",
      "0                0                  2.0            2.828886            1   \n",
      "1                2                  2.0            2.828886            1   \n",
      "2                2                  2.0            2.828886            1   \n",
      "3                2                  2.0            2.828886            1   \n",
      "4                2                  2.0            2.828886            1   \n",
      "...            ...                  ...                 ...          ...   \n",
      "1720             2                  2.0            2.828886           14   \n",
      "1721             3                  2.0            2.828886           14   \n",
      "1722             2                  2.0            2.828886           14   \n",
      "1723             2                  2.0            2.828886           14   \n",
      "1724             2                  2.0            2.828886           14   \n",
      "\n",
      "                            geometry  \n",
      "0     POINT (814726.253 5675331.610)  \n",
      "1     POINT (814733.859 5675327.157)  \n",
      "2     POINT (814741.236 5675322.199)  \n",
      "3     POINT (814748.171 5675317.124)  \n",
      "4     POINT (814755.414 5675312.649)  \n",
      "...                              ...  \n",
      "1720  POINT (814771.657 5674906.439)  \n",
      "1721  POINT (814766.737 5674911.950)  \n",
      "1722  POINT (814762.845 5674915.682)  \n",
      "1723  POINT (814757.906 5674919.552)  \n",
      "1724  POINT (814753.443 5674922.982)  \n",
      "\n",
      "[1725 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Distanz zwischen den einzelnen Punkten herausfinden\n",
    "tracks_df_dis = tracks_df_seg_med.sort_values(['trkseg_id','pt_id'],ascending = [True, True])\n",
    "tracks_df_dis_seg = pd.DataFrame()\n",
    "\n",
    "target_crs = 'EPSG:25832'\n",
    "\n",
    "for trkseg_id in range(1, max(tracks_df_dis['segment_med']) + 1):\n",
    "    rs = tracks_df_dis[tracks_df_dis['segment_med'] == trkseg_id]\n",
    "    \n",
    "    # Create a GeoDataFrame from the subset of points rs\n",
    "    rs_gdf = gpd.GeoDataFrame(rs, geometry=gpd.points_from_xy(rs['lon'], rs['lat']), crs='EPSG:4326')\n",
    "    \n",
    "    # Transform the GeoDataFrame to EPSG:25832\n",
    "    rs_gdf = rs_gdf.to_crs(target_crs)\n",
    "    \n",
    "    # Update the geometry of rs with the transformed geometry\n",
    "    rs['geometry'] = rs_gdf['geometry']\n",
    "    \n",
    "    # Rest of your calculations and operations with rs\n",
    "\n",
    "    tracks_df_dis_seg = pd.concat([tracks_df_dis_seg, rs])\n",
    "column_names_dis = tracks_df_dis_seg.columns.values.tolist()\n",
    "print(tracks_df_dis_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "31\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# Segmentierung wenn die durchschnittliche Geschwindigkeit zwischen Punkten die innerhalb einer Minute liegen kleiner als 0,5m/s. Messungenauigkeit und/oder Wechsel des Verkehrsmittels\n",
    "## Distanz zwischen 2 punkten\n",
    "tracks_df_seg = tracks_df_seg_med\n",
    "tracks_df_seg['block_gesch'] = 0 # Zeit des jetzigen Punktes und die der darauffolgenden Punkte die innerhaklb von 60sec liegen\n",
    "tracks_df_gesch = pd.DataFrame()\n",
    "segment_gesch = 0\n",
    "for trkseg in range(1,2):#max(tracks_df_seg['segment_med'])+1):\n",
    "    rs = tracks_df_seg[tracks_df_seg['segment_med'] == trkseg]\n",
    "    zeit = 0\n",
    "    start_row = 0\n",
    "    for row in range(len(rs)-1):\n",
    "        zeit += rs['zeit_abstand'].iloc[row]\n",
    "        \n",
    "        if zeit <= 30:\n",
    "            end_row = row + 1\n",
    "        else:\n",
    "            print(zeit)\n",
    "            start_row = row + 1\n",
    "            end_row = row + 1\n",
    "            zeit = 0\n",
    "    tracks_df_gesch = pd.concat([tracks_df_gesch, rs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punkte zu Tracks/DF\n",
    "\n",
    "# Leerer GDF mit Spalten und def. CRS\n",
    "tracks_df_speeds = gpd.GeoDataFrame(columns=[\"trk_id\", \"trkseg_id\", \"duration\", \"length\", \"geometry\",\"avg_speed_in_m/s\", \"avg_speed_in_km/h\", \"max_speed_in_km/h\"], crs=\"EPSG:25832\")\n",
    "column_names_speeds = tracks_df_speeds.columns.values.tolist()\n",
    "\n",
    "rs = tracks_df_seg_med\n",
    "# GRS muss mindestens 2 Lang sein damit es eine Strecke sein kann\n",
    "for trkseg in range(1,max(rs[\"segment_med\"])):\n",
    "\n",
    "    # GDF mit Punktgeometrien aus LAt/Lon und CRS\n",
    "    filtered_rows = rs[rs[\"segment_med\"] == trkseg]\n",
    "\n",
    "    if len(filtered_rows) >= 2:\n",
    "        grs = gpd.GeoDataFrame(filtered_rows, geometry=gpd.points_from_xy(filtered_rows.lon, filtered_rows.lat), crs=\"EPSG:4326\")\n",
    "        \n",
    "        # Gruppieren nach trkseg_id und erstellen des LINESTRINGS\n",
    "        grs_grouped = grs.groupby(['segment_med']).agg({'geometry': list}).reset_index()\n",
    "        grs_grouped['geometry'] = grs_grouped['geometry'].apply(lambda x: LineString(x))\n",
    "\n",
    "        # Konvertierung zu 25832\n",
    "        grs_grouped = gpd.GeoDataFrame(grs_grouped, geometry='geometry', crs=\"EPSG:4326\")\n",
    "        grs_grouped = grs_grouped.to_crs(25832)\n",
    "        # Zeiten bestimmen, start und ende\n",
    "        first_time = grs['time'].iloc[0]\n",
    "        last_time = grs['time'].iloc[-1]\n",
    "        if first_time is not None and last_time is not None:\n",
    "            first_time = datetime.combine(datetime.today().date(), first_time)\n",
    "            last_time = datetime.combine(datetime.today().date(), last_time)\n",
    "\n",
    "            if last_time < first_time:\n",
    "                last_time += timedelta(days=1)\n",
    "\n",
    "            # Dauer des Tracks errechnen und als duration speichern\n",
    "            duration = (last_time - first_time).total_seconds()\n",
    "            if duration < 0:\n",
    "                duration += 86400  # Adding 24 hours to the duration for cross-midnight cases\n",
    "            grs_grouped['duration'] = duration\n",
    "\n",
    "            # Länbge und Durchschnittsgeschwindigkeit bestimmen\n",
    "            grs_grouped['length'] = grs_grouped.length\n",
    "            grs_grouped['avg_speed_in_m/s'] = grs_grouped['length'] / grs_grouped['duration']\n",
    "            grs_grouped['avg_speed_in_km/h'] = (grs_grouped['length'] / 1000) / (grs_grouped['duration'] / 3600)\n",
    "            # Höchstgeschwindigkeit bestimmen über 10 aufeinanderfolgende Punkte\n",
    "            for geometry in grs_grouped['geometry']:\n",
    "                speeds = []\n",
    "                point_list = geometry.coords[:] # Punkteliste aller möglichen Startpunkte\n",
    "\n",
    "                # Berechnung der Höchstgeschwindigkeit\n",
    "                for i in range(len(point_list)-5):\n",
    "                    total_distance = 0\n",
    "                    total_time = 0\n",
    "\n",
    "                    # Über die 10 Punkte iterieren\n",
    "                    for j in range(i, i + 5):\n",
    "                        current_point = Point(point_list[j])\n",
    "                        next_point = Point(point_list[j + 1])\n",
    "\n",
    "                        #  Entfernung zwischen den Punkten berechnen\n",
    "                        distance = current_point.distance(next_point)\n",
    "                        total_distance += distance\n",
    "\n",
    "                        current_x, current_y = current_point.coords[0]\n",
    "                        next_x, next_y = next_point.coords[0]\n",
    "\n",
    "                        # timestamps speichern\n",
    "                        current_time = grs['time'].iloc[j] \n",
    "                        next_time = grs['time'].iloc[j + 1]\n",
    "\n",
    "                        \n",
    "                        # Validieren (vorhandesein) der timestamps\n",
    "                        if current_time is not None and next_time is not None:\n",
    "                            current_datetime = datetime.combine(datetime.today().date(), current_time)\n",
    "                            next_datetime = datetime.combine(datetime.today().date(), next_time)\n",
    "\n",
    "                            if next_datetime < current_datetime:\n",
    "                                next_datetime += timedelta(days=1)\n",
    "\n",
    "                            # Zeitunterschied berechnen\n",
    "                            time_difference = (next_datetime - current_datetime).total_seconds()\n",
    "                            if time_difference > 0:\n",
    "                                total_time += time_difference\n",
    "                            \n",
    "\n",
    "                    # Geschwindigkeiten berechnen falls total_time > 0 ist\n",
    "                    if total_time > 0:\n",
    "                        speed_m_per_s = total_distance / total_time\n",
    "                        speed_km_per_h = (total_distance / 1000) / (total_time / 3600)\n",
    "                        #print(total_distance,total_time,speed_km_per_h)\n",
    "                        speeds.append(speed_km_per_h)\n",
    "\n",
    "\n",
    "                # Aus der Liste speeds die größte Zahl finden\n",
    "                if speeds:\n",
    "                    grs_grouped['max_speed_in_km/h'] = max(speeds)\n",
    "\n",
    "            # Einfügen der Daten in die Ziel-DF\n",
    "            tracks_df_speeds = pd.concat([tracks_df_speeds, grs_grouped],ignore_index=True)\n",
    "           \n",
    "\n",
    "# Ausgabe des Ziel-DF\n",
    "#print(tracks_df_speeds)\n",
    "\n",
    "# Speichern als GJSON\n",
    "tracks_df_speeds.to_file(\"tracks_all.geojson\", driver=\"GeoJSON\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m trkseg_id \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m99\u001b[39m):\u001b[39m#trackseg_count + 1):\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \n\u001b[0;32m      6\u001b[0m     \u001b[39m# SQL Abfrage und in pd.df\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     sql \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSELECT * FROM forschungsprojekt.daten WHERE trkseg_id = \u001b[39m\u001b[39m{\u001b[39;00mtrkseg_id\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m     rs \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_sql(sql, conn)  \n\u001b[0;32m     10\u001b[0m     \u001b[39m# Sortieren nach pt_id\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     rs \u001b[39m=\u001b[39m rs\u001b[39m.\u001b[39msort_values(\u001b[39m'\u001b[39m\u001b[39mpt_id\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tobia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\sql.py:663\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39mread_table(\n\u001b[0;32m    654\u001b[0m         sql,\n\u001b[0;32m    655\u001b[0m         index_col\u001b[39m=\u001b[39mindex_col,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    660\u001b[0m         dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    661\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 663\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mread_query(\n\u001b[0;32m    664\u001b[0m         sql,\n\u001b[0;32m    665\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[0;32m    666\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    667\u001b[0m         coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[0;32m    668\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[0;32m    669\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m    670\u001b[0m         dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[0;32m    671\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    672\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tobia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\sql.py:1738\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   1681\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_query\u001b[39m(\n\u001b[0;32m   1682\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1683\u001b[0m     sql: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1690\u001b[0m     dtype_backend: DtypeBackend \u001b[39m|\u001b[39m Literal[\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1691\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m   1692\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[39m    Read SQL query into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1694\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1736\u001b[0m \n\u001b[0;32m   1737\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1738\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(sql, params)\n\u001b[0;32m   1739\u001b[0m     columns \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mkeys()\n\u001b[0;32m   1741\u001b[0m     \u001b[39mif\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tobia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\sql.py:1562\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   1560\u001b[0m args \u001b[39m=\u001b[39m [] \u001b[39mif\u001b[39;00m params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m [params]\n\u001b[0;32m   1561\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(sql, \u001b[39mstr\u001b[39m):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcon\u001b[39m.\u001b[39;49mexec_driver_sql(sql, \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   1563\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcon\u001b[39m.\u001b[39mexecute(sql, \u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\tobia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1774\u001b[0m, in \u001b[0;36mConnection.exec_driver_sql\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1769\u001b[0m execution_options \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execution_options\u001b[39m.\u001b[39mmerge_with(\n\u001b[0;32m   1770\u001b[0m     execution_options\n\u001b[0;32m   1771\u001b[0m )\n\u001b[0;32m   1773\u001b[0m dialect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\n\u001b[1;32m-> 1774\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[0;32m   1775\u001b[0m     dialect,\n\u001b[0;32m   1776\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_statement,\n\u001b[0;32m   1777\u001b[0m     statement,\n\u001b[0;32m   1778\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1779\u001b[0m     execution_options,\n\u001b[0;32m   1780\u001b[0m     statement,\n\u001b[0;32m   1781\u001b[0m     distilled_parameters,\n\u001b[0;32m   1782\u001b[0m )\n\u001b[0;32m   1784\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\tobia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1844\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1839\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exec_insertmany_context(\n\u001b[0;32m   1840\u001b[0m         dialect,\n\u001b[0;32m   1841\u001b[0m         context,\n\u001b[0;32m   1842\u001b[0m     )\n\u001b[0;32m   1843\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1844\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_single_context(\n\u001b[0;32m   1845\u001b[0m         dialect, context, statement, parameters\n\u001b[0;32m   1846\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tobia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1984\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1981\u001b[0m     result \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39m_setup_result_proxy()\n\u001b[0;32m   1983\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1984\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[0;32m   1985\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[0;32m   1986\u001b[0m     )\n\u001b[0;32m   1988\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\tobia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2342\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2340\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2341\u001b[0m         \u001b[39massert\u001b[39;00m exc_info[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2342\u001b[0m         \u001b[39mraise\u001b[39;00m exc_info[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mwith_traceback(exc_info[\u001b[39m2\u001b[39m])\n\u001b[0;32m   2343\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   2344\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reentrant_error\n",
      "File \u001b[1;32mc:\\Users\\tobia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1965\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1963\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   1964\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1965\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[0;32m   1966\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[0;32m   1967\u001b[0m         )\n\u001b[0;32m   1969\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[0;32m   1970\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1971\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m   1972\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1976\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[0;32m   1977\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tobia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:921\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 921\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "File \u001b[1;32mc:\\Users\\tobia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\encodings\\utf_8.py:15\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(input, errors)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m### Codec APIs\u001b[39;00m\n\u001b[0;32m     13\u001b[0m encode \u001b[39m=\u001b[39m codecs\u001b[39m.\u001b[39mutf_8_encode\n\u001b[1;32m---> 15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39minput\u001b[39m, errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39mutf_8_decode(\u001b[39minput\u001b[39m, errors, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mIncrementalEncoder\u001b[39;00m(codecs\u001b[39m.\u001b[39mIncrementalEncoder):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Punkte zu Tracks/SQL\n",
    "tracks_df = gpd.GeoDataFrame(columns=[\"trk_id\",\"trkseg_id\",\"duration\", \"length\", \"geometry\", \"avg_speed_in_m/s\", \"avg_speed_in_km/h\",\"max_speed_in_km/h\",\"avg_acceleration_in_m/s2\"], crs=\"EPSG:25832\")\n",
    "\n",
    "for trkseg_id in range(1, 99):#trackseg_count + 1):\n",
    "    \n",
    "    # SQL Abfrage und in pd.df\n",
    "    sql = f\"SELECT * FROM forschungsprojekt.daten WHERE trkseg_id = {trkseg_id}\"\n",
    "    rs = pd.read_sql(sql, conn)  \n",
    "\n",
    "    # Sortieren nach pt_id\n",
    "    rs = rs.sort_values('pt_id')\n",
    "\n",
    "    # GDF mit Punktgeometrien aus LAt/Lon und CRS\n",
    "    grs = gpd.GeoDataFrame(rs, geometry=gpd.points_from_xy(rs.lon, rs.lat), crs=\"EPSG:4326\")\n",
    "\n",
    "    # GRS muss mindestens 2 Lang sein damit es eine Strecke sein kann\n",
    "    if len(grs) >= 2:\n",
    "        # Gruppieren nach trkseg_id und erstellen des LINESTRINGS\n",
    "        grs_grouped = grs.groupby(['trkseg_id']).agg({'geometry': list}).reset_index()\n",
    "        grs_grouped['geometry'] = grs_grouped['geometry'].apply(lambda x: LineString(x))\n",
    "\n",
    "        # Konvertierung zu 25832\n",
    "        grs_grouped = gpd.GeoDataFrame(grs_grouped, geometry='geometry', crs=\"EPSG:4326\")\n",
    "        grs_grouped = grs_grouped.to_crs(25832)\n",
    "\n",
    "        # Zeiten bestimmen, start und ende\n",
    "        first_time = rs['time'].iloc[0]\n",
    "        last_time = rs['time'].iloc[-1]\n",
    "        \n",
    "        # Auf gültige timesptamps überprüfen \n",
    "        if first_time is not None and last_time is not None:\n",
    "            first_time = datetime.combine(datetime.today().date(), first_time)\n",
    "            last_time = datetime.combine(datetime.today().date(), last_time)\n",
    "\n",
    "            # Dauer des Tracks errechnen und als duration speichern\n",
    "            duration = (last_time - first_time).total_seconds()\n",
    "            grs_grouped['duration'] = duration\n",
    "\n",
    "            # Länbge und Durchschnittsgeschwindigkeit bestimmen\n",
    "            grs_grouped['length'] = grs_grouped.length\n",
    "            grs_grouped['avg_speed_in_m/s'] = grs_grouped['length'] / grs_grouped['duration']\n",
    "            grs_grouped['avg_speed_in_km/h'] = (grs_grouped['length'] / 1000) / (grs_grouped['duration'] / 3600)\n",
    "                \n",
    "            # Höchstgeschwindigkeit bestimmen über 10 aufeinanderfolgende Punkte\n",
    "            for geometry in grs_grouped['geometry']:\n",
    "                speeds = []\n",
    "                point_list = geometry.coords[:-10]  # Punkteliste aller möglichen Startpunkte\n",
    "\n",
    "                # Berechnung der Höchstgeschwindigkeit\n",
    "                for i in range(0, len(point_list) - 10, 10):\n",
    "                    total_distance = 0\n",
    "                    total_time = 0\n",
    "\n",
    "                    # Über die 10 Punkte iterieren\n",
    "                    for j in range(i, i + 10):\n",
    "                        current_point = Point(point_list[j])\n",
    "                        next_point = Point(point_list[j + 1])\n",
    "\n",
    "                        #  Entfernung zwischen den Punkten berechnen\n",
    "                        distance = current_point.distance(next_point)\n",
    "                        total_distance += distance\n",
    "\n",
    "                        current_x, current_y = current_point.coords[0]\n",
    "                        next_x, next_y = next_point.coords[0]\n",
    "\n",
    "                        # timestamps speichern\n",
    "                        current_time = rs['time'].iloc[j] \n",
    "                        next_time = rs['time'].iloc[j + 1]\n",
    "\n",
    "                        # Validieren (vorhandesein) der timestamps\n",
    "                        if current_time is not None and next_time is not None:\n",
    "                            current_time = datetime.combine(datetime.today().date(), current_time)\n",
    "                            next_time = datetime.combine(datetime.today().date(), next_time)\n",
    "\n",
    "                            # Zeitunterschied berechnen\n",
    "                            time_difference = (next_time - current_time).total_seconds()\n",
    "\n",
    "                            if time_difference > 0:\n",
    "                                total_time += time_difference\n",
    "\n",
    "                    # Geschwindigkeiten berechnen falls total_time > 0 ist\n",
    "                    if total_time > 0:\n",
    "                        speed_m_per_s = total_distance / total_time\n",
    "                        speed_km_per_h = (total_distance / 1000) / (total_time / 3600)\n",
    "                        speeds.append(speed_km_per_h)\n",
    "\n",
    "                # Aus der Liste speeds die größte Zahl finden\n",
    "                if speeds:\n",
    "                    grs_grouped['max_speed_in_km/h'] = max(speeds)\n",
    "\n",
    "            # Beschleunigung bestimmen über 5 aufeinanderfolgende Punkte\n",
    "            #for geometry in grs_grouped['geometry']:\n",
    "            #    accelerations = []\n",
    "            #    point_list = geometry.coords[:-5]\n",
    "\n",
    "            #    # Berechnung der Beschleunigung\n",
    "            #    for i in range(0, len(point_list) - 5, 5):\n",
    "            #        total_speed_change = 0\n",
    "            #        total_time = 0\n",
    "\n",
    "            #        # Über die 5 Punkte iterieren\n",
    "            #        for j in range(i, i + 5):\n",
    "            #            current_point = Point(point_list[j])\n",
    "            #            next_point = Point(point_list[j + 1])\n",
    "\n",
    "                        # Entfernung zwischen den Punkten berechnen\n",
    "            #           distance = current_point.distance(next_point)\n",
    "\n",
    "            #           current_speed = grs_grouped['avg_speed_in_m/s'].iloc[j]\n",
    "            #            next_speed = grs_grouped['avg_speed_in_m/s'].iloc[j + 1]\n",
    "\n",
    "                        # Calculate speed change (acceleration)\n",
    "            #            speed_change = next_speed - current_speed\n",
    "            #            total_speed_change += speed_change\n",
    "\n",
    "                        # timestamps speichern\n",
    "            #            current_time = rs['time'].iloc[j]\n",
    "            #            next_time = rs['time'].iloc[j + 1]\n",
    "\n",
    "                    # Validieren (vorhandesein) der timestamps\n",
    "            #            if current_time is not None and next_time is not None:\n",
    "            #                current_time = datetime.combine(datetime.today().date(), current_time)\n",
    "            #                next_time = datetime.combine(datetime.today().date(), next_time)\n",
    "\n",
    "                            # Zeitunterschied berechnen\n",
    "            #                time_difference = (next_time - current_time).total_seconds()\n",
    "\n",
    "            #                if time_difference > 0:\n",
    "            #                    total_time += time_difference\n",
    "\n",
    "                    # Beschleunigung berechnen falls total_time > 0 ist\n",
    "            #        if total_time > 0:\n",
    "            #            acceleration_m_per_s2 = total_speed_change / total_time\n",
    "            #            acceleration_km_per_h2 = (total_speed_change / 1000) / (total_time / 3600)\n",
    "            #            accelerations.append(acceleration_km_per_h2)\n",
    "\n",
    "                # Aus der Liste accelerations die größte Zahl finden\n",
    "            #    if accelerations:\n",
    "            #        grs_grouped['max_acceleration_in_km/h2'] = max(accelerations)\n",
    "\n",
    "        # Einfügen der Daten in die Ziel-DF\n",
    "        tracks_df = pd.concat([tracks_df, grs_grouped])\n",
    "\n",
    "print(tracks_df)\n",
    "tracks_df.to_file(\"tracks_all.geojson\", driver=\"GeoJSON\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
