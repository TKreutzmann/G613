{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Benötigte Packages\n",
    "import os\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grundeinstellungen\n",
    "\n",
    "# bestandteile der URL\n",
    "## alle Zahlen in Grad\n",
    "\n",
    "lons = [13.6]  # linker Rand\n",
    "lats = [51.0]  # unterer Rand\n",
    "zellweite_Lon = 0.1  # pro 0.1 ist die Zelle ca 7km breiter/schmaler\n",
    "zellweite_Lat = 0.1  # pro 0.1 ist die Zelle ca 11km höher/niedriger\n",
    "url1 = 'https://api.openstreetmap.org/api/0.6/trackpoints?bbox='  # bestandteile URL\n",
    "url2 = '&page='  # bestandteile URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BBOX und URL\n",
    "# Schleife für das erstellen der Dateien und hinzufügen der Punkte zu einem df\n",
    "for lon in lons:\n",
    "    for lat in lats:\n",
    "        bbox = f\"{lon},{lat},{lon + zellweite_Lon},{lat + zellweite_Lat}\"  # erstellen der BBOX\n",
    "        page = 0\n",
    "        os.makedirs(\"osmtracks\", exist_ok=True)  # Ordner erstellen um die .gpx zu speichern\n",
    "        while True:\n",
    "            url = f\"{url1}{bbox}{url2}{page}\"\n",
    "            response = requests.get(url)\n",
    "            filestring = f\"osmtracks/tracks_{page}.gpx\"  # Dateipfad und Name\n",
    "            with open(filestring, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "            \n",
    "            # datei direkt in xml umwandeln\n",
    "            new_files = filestring.replace(\".gpx\", \".xml\")\n",
    "            os.rename(filestring, new_files)\n",
    "    \n",
    "            page += 1  # Page um eins erhöhen\n",
    "            \n",
    "            size = os.path.getsize(new_files)  # Dateigröße für Abbruchbedingung\n",
    "            # Abbruchbedingung sehr wichtig, sonst wiederholt sich die letzte Page unendlich oft, bessere Alternative als\n",
    "            # Dateigröße finden\n",
    "            if size < 500000:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benötigte Dataframes usw.\n",
    "tracks_df = pd.DataFrame(columns=[\"lat\", \"lon\", \"time\", \"seg_id\", \"pt_id\", \"name\"])\n",
    "track_df = pd.DataFrame(columns=[\"lat\", \"lon\", \"time\", \"seg_id\", \"pt_id\", \"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m             pt_id \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     23\u001b[0m             new_row \u001b[39m=\u001b[39m [lat, lon, time, seg_id, pt_id, name]\n\u001b[1;32m---> 24\u001b[0m             track_df\u001b[39m.\u001b[39mloc[\u001b[39mlen\u001b[39m(track_df)] \u001b[39m=\u001b[39m new_row\n\u001b[0;32m     26\u001b[0m tracks_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([tracks_df, track_df], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m track_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mlat\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlon\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mseg_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpt_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\tobia\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    817\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[1;32m--> 818\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\tobia\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1785\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1782\u001b[0m     indexer, missing \u001b[39m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m missing:\n\u001b[1;32m-> 1785\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_missing(indexer, value)\n\u001b[0;32m   1786\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mloc\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1789\u001b[0m     \u001b[39m# must come after setting of missing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tobia\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:2182\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   2180\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_mgr \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39m_mgr\n\u001b[0;32m   2181\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_append(value)\u001b[39m.\u001b[39m_mgr\n\u001b[0;32m   2183\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_maybe_update_cacher(clear\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\tobia\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:9808\u001b[0m, in \u001b[0;36mDataFrame._append\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   9805\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   9806\u001b[0m     to_concat \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m, other]\n\u001b[1;32m-> 9808\u001b[0m result \u001b[39m=\u001b[39m concat(\n\u001b[0;32m   9809\u001b[0m     to_concat,\n\u001b[0;32m   9810\u001b[0m     ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[0;32m   9811\u001b[0m     verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[0;32m   9812\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   9813\u001b[0m )\n\u001b[0;32m   9814\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mappend\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tobia\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tobia\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39m1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    368\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m     objs,\n\u001b[0;32m    370\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    378\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[0;32m    379\u001b[0m )\n\u001b[1;32m--> 381\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[1;32mc:\\Users\\tobia\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    614\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 616\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[0;32m    617\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes, concat_axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbm_axis, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[0;32m    618\u001b[0m )\n\u001b[0;32m    619\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy:\n\u001b[0;32m    620\u001b[0m     new_data\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\Users\\tobia\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py:233\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    231\u001b[0m     fastpath \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m values\u001b[39m.\u001b[39mdtype\n\u001b[0;32m    232\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 233\u001b[0m     values \u001b[39m=\u001b[39m _concatenate_join_units(join_units, concat_axis, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    234\u001b[0m     fastpath \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m fastpath:\n",
      "File \u001b[1;32mc:\\Users\\tobia\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py:577\u001b[0m, in \u001b[0;36m_concatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m    574\u001b[0m     concat_values \u001b[39m=\u001b[39m ensure_block_shape(concat_values, \u001b[39m2\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     concat_values \u001b[39m=\u001b[39m concat_compat(to_concat, axis\u001b[39m=\u001b[39;49mconcat_axis)\n\u001b[0;32m    579\u001b[0m \u001b[39mreturn\u001b[39;00m concat_values\n",
      "File \u001b[1;32mc:\\Users\\tobia\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\concat.py:151\u001b[0m, in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[0;32m    148\u001b[0m             to_concat \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mastype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m to_concat]\n\u001b[0;32m    149\u001b[0m             kinds \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mo\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m--> 151\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate(to_concat, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m    152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kinds \u001b[39mand\u001b[39;00m result\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    153\u001b[0m     \u001b[39m# GH#39817\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    155\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBehavior when concatenating bool-dtype and numeric-dtype arrays is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdeprecated; in a future version these will cast to object dtype \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    161\u001b[0m     )\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "files = []\n",
    "\n",
    "for file in os.listdir(\"/Forschungsprojekt/osmtracks\"):\n",
    "    if file.endswith(\"tracks_0.xml\"):\n",
    "        files.append(file)\n",
    "\n",
    "for file in files:\n",
    "    tree = ET.parse(\"/Forschungsprojekt/osmtracks/\" + file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for trk in root.findall(\".//{http://www.topografix.com/GPX/1/0}trk\"):\n",
    "        seg_counter = 0\n",
    "        for trkseg in trk.findall(\".//{http://www.topografix.com/GPX/1/0}trkseg\"):\n",
    "            seg_counter += 1\n",
    "            seg_id = seg_counter\n",
    "            pt_id = 0\n",
    "            for trkpt in trkseg.findall(\".//{http://www.topografix.com/GPX/1/0}trkpt\"):\n",
    "                lat = trkpt.get(\"lat\")\n",
    "                lon = trkpt.get(\"lon\")\n",
    "                time = trkpt.find(\".//{http://www.topografix.com/GPX/1/0}time\").text if trkpt.find(\".//{http://www.topografix.com/GPX/1/0}time\") is not None else \"NA\"\n",
    "                name = trkpt.find(\".//{http://www.topografix.com/GPX/1/0}name\").text if trkpt.find(\".//{http://www.topografix.com/GPX/1/0}name\") is not None else \"NoName\"\n",
    "                pt_id += 1\n",
    "                new_row = [lat, lon, time, seg_id, pt_id, name]\n",
    "                track_df.loc[len(track_df)] = new_row\n",
    "\n",
    "    tracks_df = pd.concat([tracks_df, track_df], ignore_index=True)\n",
    "    track_df = pd.DataFrame(columns=[\"lat\", \"lon\", \"time\", \"seg_id\", \"pt_id\", \"name\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
