{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Benötigte Packages\n",
    "import os\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "from pyproj import Transformer, Geod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grundeinstellungen\n",
    "\n",
    "# bestandteile der URL\n",
    "## alle Zahlen in Grad\n",
    "\n",
    "lon = [13.5]  # linker Rand\n",
    "lat = [50.9]  # unterer Rand\n",
    "zellweite_lon = [0.5]  # pro 0.1 ist die Zelle ca 7km breiter/schmaler\n",
    "zellweite_lat = [0.3]  # pro 0.1 ist die Zelle ca 11km höher/niedriger\n",
    "url1 = 'https://api.openstreetmap.org/api/0.6/trackpoints?bbox='  # bestandteile URL\n",
    "url2 = '&page='  # bestandteile URL\n",
    "bbox_str = f\"{str(lon[0])},{str(lat[0])},{str(float(lon[0]+zellweite_lon[0]))},{str(float(lat[0]+zellweite_lat[0]))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of processes to use\n",
    "bbox = bbox_str  # erstellen der BBOX\n",
    "page = 0\n",
    "os.makedirs(\"osmtracks\", exist_ok=True)  # Ordner erstellen um die .gpx zu speichern\n",
    "while True:\n",
    "    url = f\"{url1}{bbox}{url2}{page}\"\n",
    "    response = requests.get(url)\n",
    "    filestring = f\"osmtracks/tracks_{page}.gpx\"  # Dateipfad und Name\n",
    "    with open(filestring, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "            \n",
    "    # datei direkt in xml umwandeln\n",
    "    new_files = filestring.replace(\".gpx\", \".xml\")\n",
    "    os.rename(filestring, new_files)\n",
    "    \n",
    "    page += 1  # Page um eins erhöhen\n",
    "            \n",
    "    size = os.path.getsize(new_files)  # Dateigröße für Abbruchbedingung\n",
    "    # Abbruchbedingung sehr wichtig, sonst wiederholt sich die letzte Page unendlich oft, bessere Alternative als\n",
    "    # Dateigröße finden\n",
    "    if size < 500000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benötigte Dataframes usw.\n",
    "tracks_df = pd.DataFrame(columns=[\"lat\", \"lon\", \"time\", \"trk_id\",\"trkseg_id\", \"pt_id\", \"name\"])\n",
    "track_df = pd.DataFrame(columns=[\"lat\", \"lon\", \"time\", \"trk_id\",\"trkseg_id\", \"pt_id\", \"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "\n",
    "for file in os.listdir(\"/Forschungsprojekt/G613/osmtracks/\"):\n",
    "    if file.endswith(\"_0.xml\"):\n",
    "        files.append(file)\n",
    "\n",
    "trkseg_id = 0    \n",
    "trk_id = 0\n",
    "for file in files:\n",
    "    tree = ET.parse(\"/Forschungsprojekt/G613/osmtracks/\" + file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    \n",
    "    for trk in root.findall(\".//{http://www.topografix.com/GPX/1/0}trk\"):\n",
    "        trk_id += 1\n",
    "        for trkseg in trk.findall(\".//{http://www.topografix.com/GPX/1/0}trkseg\"):\n",
    "            trkseg_id +=1\n",
    "            pt_id = 0\n",
    "            for trkpt in trkseg.findall(\".//{http://www.topografix.com/GPX/1/0}trkpt\"):\n",
    "\n",
    "                lat = trkpt.get(\"lat\")\n",
    "                lon = trkpt.get(\"lon\")\n",
    "\n",
    "                time_element = trkpt.find(\".//{http://www.topografix.com/GPX/1/0}time\")\n",
    "                if time_element is not None:\n",
    "                    time = time_element.text\n",
    "                    if time.startswith('0000'):\n",
    "                       time = '1970' + time[4:] \n",
    "                    time = pd.to_datetime(time)\n",
    "                    time_str = time.strftime('%H:%M:%S')\n",
    "                else:\n",
    "                    time_str = None\n",
    "\n",
    "                name = trkpt.find(\".//{http://www.topografix.com/GPX/1/0}name\").text if trkpt.find(\".//{http://www.topografix.com/GPX/1/0}name\") is not None else \"NoName\"\n",
    "\n",
    "                pt_id += 1\n",
    "\n",
    "                \n",
    "                new_row = [lat, lon, time_str, trk_id,trkseg_id, pt_id, name]\n",
    "                track_df.loc[len(track_df)] = new_row\n",
    "\n",
    "    tracks_df = pd.concat([tracks_df, track_df], ignore_index=True)\n",
    "    track_df = pd.DataFrame(columns=[\"lat\", \"lon\", \"time\", \"trk_id\",\"trkseg_id\", \"pt_id\", \"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aus Zeitstempel den Zeitlichen Abstand herausfinden\n",
    "\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:25832\", always_xy=True)\n",
    "geod = Geod(ellps=\"WGS84\")\n",
    "pd.options.mode.chained_assignment = None\n",
    "tracks_df = tracks_df.sort_values(['trkseg_id','pt_id'],ascending = [True, True])\n",
    "tracks_df_time = pd.DataFrame()\n",
    "for trkseg_id in range(1,max(tracks_df['trkseg_id'])+1):# trackseg_count + 1):\n",
    "    rs = tracks_df[tracks_df['trkseg_id'] == trkseg_id]\n",
    "\n",
    "    rs['time'] = pd.to_datetime(rs['time'], format='%H:%M:%S').dt.time\n",
    "    rs['zeit_abstand'] = 0\n",
    "    rs['median_zeit_abstand'] = 0\n",
    "    rs['durch_zeit_abstand'] = 0\n",
    "\n",
    "    current_time = rs['time'].iloc[0]\n",
    "    if current_time is not None:\n",
    "        for pt_id in range(len(rs)):\n",
    "            if rs['pt_id'].iloc[pt_id] == 1:\n",
    "                rs['zeit_abstand'] = 0\n",
    "            else:\n",
    "                last_time = rs['time'].iloc[pt_id - 1]\n",
    "                current_time = rs['time'].iloc[pt_id]\n",
    "\n",
    "                abstand_seconds = (current_time.hour - last_time.hour) * 3600 + \\\n",
    "                                  (current_time.minute - last_time.minute) * 60 + \\\n",
    "                                  (current_time.second - last_time.second)\n",
    "                rs['zeit_abstand'].iloc[pt_id] = abstand_seconds\n",
    "\n",
    "    rs['median_zeit_abstand'] = rs['zeit_abstand'].tail(-1).median()\n",
    "    rs['durch_zeit_abstand'] = rs['zeit_abstand'].tail(-1).mean()\n",
    "\n",
    "    tracks_df_time = pd.concat([tracks_df_time, rs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string = \"postgresql://postgres:Nummer11!@localhost/postgres\"\n",
    "db = create_engine(conn_string)\n",
    "conn = db.connect()\n",
    "\n",
    "column_types = {\n",
    "    \"lat\": sqlalchemy.Float,\n",
    "    \"lon\": sqlalchemy.Float,\n",
    "    \"time\": sqlalchemy.Time,\n",
    "    \"trk_id\": sqlalchemy.Integer,\n",
    "    \"pt_id\": sqlalchemy.Integer,\n",
    "    \"name\": sqlalchemy.String\n",
    "}\n",
    "\n",
    "tracks_df.to_sql('daten', conn, 'forschungsprojekt', if_exists=\"replace\", index=False, dtype=column_types)\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
